# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00a_HelperFunctions.helper_functions.ipynb (unless otherwise specified).

# __all__ = ['list_imported_modules', 'supress_warning', 'getDictKey',
# 'delegates_fastai', 'delegates', 'custom_dir', 'GetAttr',
# 'combineClassesInDf', 'create_docs']

#%%
# inspect: for decorator: "delegate"
import inspect, os, glob, yaml, torch
# from ..data_io import image_io
# from ..data_io.image_io import *
from ..data_io import faisal_io # for read_config <= faisal_label_list_name2id

from fastai.basics import * # for read_config
from ..models import losses as ls
from ..models.losses import *
# from ..models.losses import FocalLoss
# from ..models.SegLoss.losses_pytorch import lovasz_loss, dice_loss, focal_loss, boundary_loss
#%%%%%%%%%%%%%%%%% Helper Functions %%%%%%%%%%%%%%%%%
# delegates functino duplicated to helper_functions
def delegates(to=None, keep=False):
    '''Decorator: replace `**kwargs` in signature with params from `to`
    A replacement of fastai's native one to support @delegates decorator for multiple inheritance
    > Ref: https://forums.fast.ai/t/delegates-decorator-for-multiple-inheritance/57192
    > Ref: https://fastcore.fast.ai/foundation#delegates
    '''
    def _f(f):
        from_f = f.__init__ if to is None else f
        sig = inspect.signature(from_f)
        sigd = dict(sig.parameters)
        k = sigd.pop('kwargs')
        if to is None:
            for base_cls in f.__bases__:
                to_f = base_cls.__init__
                s2 = {k:v for k,v in inspect.signature(to_f).parameters.items()
                    if v.default != inspect.Parameter.empty and k not in sigd}
                sigd.update(s2)
        else:
            to_f = to
            s2 = {k:v for k,v in inspect.signature(to_f).parameters.items()
                if v.default != inspect.Parameter.empty and k not in sigd}
            sigd.update(s2)
        if keep: sigd['kwargs'] = k
        from_f.__signature__ = sig.replace(parameters=sigd.values())
        return f
    return _f

# Cell
def list_imported_modules():
    '''
    check current imported modules
    Ref: https://chrisyeh96.github.io/2017/08/08/definitive-guide-python-imports.html#case-4-importing-from-parent-directory
    '''
    import pkgutil
    search_path = None # set to None to see all modules importable from sys.path
    all_modules = [x[1] for x in pkgutil.iter_modules(path=search_path)]
    print(all_modules)
    return all_modules

# Cell
def supress_warning():
  # %% to suppress the warning
  # Ref 1: https://forums.fast.ai/t/lesson-2-download-cannot-run-the-code/57308/4
  # Ref 2: https://forums.fast.ai/t/warnings-when-trying-to-make-an-imagedatabunch/56323
  import warnings
  warnings.filterwarnings("ignore", category=UserWarning, module="torch.nn.functional")
  warnings.filterwarnings("ignore", category=UserWarning, module="torch.nn.Modules")
  warnings.filterwarnings("ignore", category=UserWarning, module="torchvision.models")
  return warnings

# Cell
def getDictKey(mDict,value):
  '''Get dictionary key given value'''
  return list(mDict.keys())[list(mDict.values()).index(value)]

# Cell

#%% ######## delegate decorator from fastai v2
# Reference: https://www.fast.ai/2019/08/06/delegation/

# delegates for class/function
def delegates_fastai(to=None, keep=False):
    '''Decorator: replace `**kwargs` in signature with params from `to`
    extracted from fastai v2
    Ref: https://fastcore.fast.ai/foundation#delegates'''
    def _f(f):
        if to is None: to_f,from_f = f.__base__.__init__,f.__init__
        else:          to_f,from_f = to,f
        sig = inspect.signature(from_f)
        sigd = dict(sig.parameters)
        k = sigd.pop('kwargs')
        s2 = {k:v for k,v in inspect.signature(to_f).parameters.items()
              if v.default != inspect.Parameter.empty and k not in sigd}
        sigd.update(s2)
        if keep: sigd['kwargs'] = k
        from_f.__signature__ = sig.replace(parameters=sigd.values())
        return f
    return _f

def delegates(to=None, keep=False):
    '''Decorator: replace `**kwargs` in signature with params from `to`
    A replacement of fastai's native one to support @delegates decorator for multiple inheritance
    > Ref: https://forums.fast.ai/t/delegates-decorator-for-multiple-inheritance/57192
    > Ref: https://fastcore.fast.ai/foundation#delegates
    '''
    def _f(f):
        from_f = f.__init__ if to is None else f
        sig = inspect.signature(from_f)
        sigd = dict(sig.parameters)
        k = sigd.pop('kwargs')
        if to is None:
            for base_cls in f.__bases__:
                to_f = base_cls.__init__
                s2 = {k:v for k,v in inspect.signature(to_f).parameters.items()
                    if v.default != inspect.Parameter.empty and k not in sigd}
                sigd.update(s2)
        else:
            to_f = to
            s2 = {k:v for k,v in inspect.signature(to_f).parameters.items()
                if v.default != inspect.Parameter.empty and k not in sigd}
            sigd.update(s2)
        if keep: sigd['kwargs'] = k
        from_f.__signature__ = sig.replace(parameters=sigd.values())
        return f
    return _f
# Cell

# Delegates for composition function
def custom_dir(c, add):
  return dir(type(c)) + list(c.__dict__.keys()) + add

class GetAttr:
    "Base class for attr accesses in `self._xtra` passed down to `self.default`"
    @property
    def _xtra(self): return [o for o in dir(self.default) if not o.startswith('_')]
    def __getattr__(self,k):
        if k in self._xtra: return getattr(self.default, k)
        raise AttributeError(k)
    def __dir__(self): return custom_dir(self, self._xtra)

#%%
# create a copy of function with different function name
def copy_func(f, name=None):
    '''
    return a function with same code, globals, defaults, closure, and
    name (or provide a new name)
    # Ref: https://stackoverflow.com/questions/6527633/how-can-i-make-a-deepcopy-of-a-function-in-python
    '''
    import types
    fn = types.FunctionType(f.__code__, f.__globals__, name or f.__name__, f.__defaults__, f.__closure__)
    # in case f was given attrs (note this dict is a shallow copy):
    fn.__dict__.update(f.__dict__)
    return fn

# Cell
def combineClassesInDf(df, col:str, colNew=None, classes:list=[], classNew:str='', deep=True):
  '''combine multiple class into a single in a dataframe'''
  # define new dataFrame to be returned
  dfNew = df.copy(deep=deep)
  # generate new colume if necessary
  if colNew is None: colNew=col
  dfNew[colNew]=dfNew[col]
  # Get the indexes to be replaced
  classesIdx = dfNew.index[dfNew.loc[:,colNew].isin(classes)]
  # generate new class
  dfNew.loc[classesIdx,colNew] = classNew
  return dfNew

#%%
# Cell
def update_config(cfg, verbose=False, device='cuda', **kwargs):
  from ..models.losses import SegLossFlat
  #%% modify cfg 
  # General
  for k, v in cfg.items():
    if cfg[k] == 'None': cfg[k] = None

  if 'base_lr' in cfg.keys() and cfg['base_lr'] is not None:
    cfg['base_lr'] = float(cfg['base_lr'])

  # if not 'threshold' in cfg.keys(): cfg['threshold'] = None
  # # 'thres' is the internally-used parameters
  # cfg['thres'] = cfg['threshold']

  # Loss function
  # Ref: https://techcommunity.microsoft.com/t5/ai-customer-engineering-team/simple-and-easy-distributed-deep-learning-with-fast-ai-on-azure/ba-p/1434685

  if 'loss_func' in cfg.keys():
    # Dice Losses
    if cfg['loss_func'] == "DiceLossMonai":
      cfg['loss_func'] = SegLossFlat(ls.DiceLossMonai, include_background=False, to_onehot_y=False, softmax=True, flatten=False)
    elif cfg['loss_func'] == 'DC_Loss':
      cfg['loss_func'] = SegLossFlat(ls.DC_Loss, take_log=False, flatten=False)
    elif cfg['loss_func'] == 'DC_Loss_log':
      cfg['loss_func'] = SegLossFlat(ls.DC_Loss, take_log=True, flatten=False)
    elif cfg['loss_func'] == 'GDC_Loss':
      cfg['loss_func'] = SegLossFlat(ls.GDC_Loss, take_log=False, flatten=False)
    elif cfg['loss_func'] == 'GDC_Loss_log':
      cfg['loss_func'] = SegLossFlat(ls.GDC_Loss, take_log=True, flatten=False)
    elif cfg['loss_func'] == 'LovaszSoftmaxLoss':
      cfg['loss_func'] == SegLossFlat(lovasz_loss.LovaszSoftmax, flatten=False)
    # if cfg['loss_func'] == 'SDC_Loss': # soft dice coefficient not working
    #   cfg['loss_func'] = SegLossFlat(SDC_Loss, flatten=False)

    # Cross Entropy Losses
    elif cfg['loss_func'] == 'CrossEntropyLossFlat':
      cfg['loss_func'] = CrossEntropyLossFlat(axis=1)
    elif cfg['loss_func'] == 'CrossEntropyLossFlatWeighted':
      # Use overall weights
      cfg['loss_func'] = CrossEntropyLossFlat(axis=1, weight=torch.Tensor(cfg['class_weights']).to(device))   
    elif cfg['loss_func'] == 'WeightedCrossEntropyLoss':
      # use batch-weights (with the option to add additional weight)
      cfg['loss_func'] = SegLossFlat(ls.WeightedCrossEntropyLoss, flatten=False)
    # Focus Loss
    elif cfg['loss_func'] == 'Focal_Loss':
      cfg['loss_func'] = SegLossFlat(ls.FocalLoss)
    # Composite Losses
    elif cfg['loss_func'] == 'DC_Focus':
      cfg['loss_func'] = SegLossFlat(ls.DC_Focal_Loss, alpha=10., gamma=2., flatten=False)
    elif cfg['loss_func'] == 'GDC_Focus':
      cfg['loss_func'] = SegLossFlat(ls.GDC_Focal_Loss, alpha=10., gamma=2., flatten=False)
    elif isinstance(cfg['loss_func'], str): # generalized methods to convert loss function to be fastai compatible
      cfg['loss_func'] = SegLossFlat(cfg['loss_func'], flatten=False, **kwargs)

  if verbose is True: print(f'{cfg}')

  return cfg

def read_config(cfg_path, convert=True, verbose=False, convert_codes=True):
  ''' Read config (yaml) files
  > Ref: Ref: https://towardsdatascience.com/5-reasons-to-use-yaml-files-in-your-machine-learning-projects-d4c7b9650f27
  '''
  try:
    with open(cfg_path, 'r') as file:
      cfg = yaml.safe_load(file)
  except Exception as e:
    print(f'Error reading the config file {cfg_path}')

  if convert is True:
    cfg = update_config(cfg)

  if verbose is True: print(f'{cfg}')

  # will prioritize to use codes file above labelFile to determine code
  if ("labelFile" in cfg.keys()) and ("codes" not in cfg.keys()):
    labelFile = cfg['labelFile']
    # label_df = pd.read_csv(labelFile, header=None).sort_values(by=[1])
    codes = list(pd.read_csv(labelFile, header=None)[0])
    # convert hyphen and space into underscore in codes (to be compatible to Matlab)
    if convert_codes is True:
      for i,code in enumerate(codes):
        codes[i] = code.replace("-","_").replace(" ","_")
    # build `codes` in cfg (= tissue_names)
    cfg['codes'] = codes
    cfg['labellist'] = faisal_io.faisal_label_list_name2id(codes)

  if ("label_list_preserve" in cfg.keys()):
    # if isinstance(cfg['label_list_preserve'],(str,Path)):
      # === old v0 format ===
      # cfg['label_list_preserve']=np.array(pd.read_csv(cfg['label_list_preserve'],header=None)[1])
      # === new v1 format ===
    cfg['label_list_preserve'] = faisal_io.faisal_label_list_name2id(cfg['label_list_preserve'])
      # tissue_settings = faisal_io.faisal_abacs_getStandardTissueSettings()
      # labelIdx = tissue_settings['labelIdx']
      # label_list_preserve = pd.read_csv(label_list_preserve, header=None)[0].values
      # label_list_preserve = [labelIdx[labelname] for labelname in label_list_preserve]
  
  # deetermine validation set
  # if ("ValidListFile" in cfg.keys()) and ("validlist" not in cfg.keys()):
  if ("validlist" in cfg.keys()) and (isinstance(cfg['validlist'], (str,Path))): 
    cfg['validlist'] = list(pd.read_csv(cfg['validlist'], header=None)[0])

  return cfg

def dict2zip(input_dict:dict):
  input_list = list(input_dict.items())
  output_zip = zip(*input_list)
  return output_zip

# Cell
def create_docs(lib_dir):
    ''' To automatically create documents for the library
    - Input:
        -- lib_dir: Library directory
    '''
    return None
